{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48c2da6-33e4-4d6f-b579-f9ffa30c695d",
   "metadata": {},
   "source": [
    "**Encoding** in Machine Learning (ML) means converting categorical (text / label) data into numerical form, because ML algorithms work with numbers, not strings.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"location\" = Bangalore, Mumbai, Delhi â†’ ML cannot directly process these values.\n",
    "\n",
    "Why Encoding Is Required\n",
    "\n",
    "1. ML models perform mathematical operations\n",
    "\n",
    "2. Text data has no inherent numeric meaning\n",
    "\n",
    "3. Encoding prevents model errors\n",
    "\n",
    "4. Proper encoding improves accuracy & generalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d130f8-a62c-4f2b-aa7d-6f68d11a4476",
   "metadata": {},
   "source": [
    "# 1. Label Encoding\n",
    "\n",
    "**Label Encoding** assigns each category a unique integer. It is simple and memory-efficient but may unintentionally imply an order among categories when none exists.\n",
    "\n",
    "1. Used in tree-based models like Decision Trees or XGBoost.\n",
    "\n",
    "2. Pros: Simple and memory-efficient.\n",
    "\n",
    "3. Cons: Introduces implicit order which may be misinterpreted by non-tree models when used with nominal data.\n",
    "\n",
    "**when to use** \n",
    "\n",
    "Ordinal categorical data (order matters)\n",
    "\n",
    "Tree-based models (Decision Tree, Random Forest)\n",
    "\n",
    "Example Columns\n",
    "\n",
    "size â†’ 1 BHK, 2 BHK, 3 BHK\n",
    "\n",
    "grade â†’ A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd5ca0d-43ff-4b54-9175-1da4c9cc8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Data: [0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = ['Grade A', 'Grade B', 'Grade c', 'Grade A']\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded_data = le.fit_transform(data)\n",
    "print(f\"Encoded Data: {encoded_data}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e64a733-7a9f-4939-988b-5de932801be2",
   "metadata": {},
   "source": [
    "# 2. One-Hot Encoding\n",
    "\n",
    "**One-Hot Encoding** converts categories into binary columns with each column representing one category. It prevents false ordering but can lead to high dimensionality if there are many unique values.\n",
    "\n",
    "1. Used in linear models, logistic regression and neural networks.\n",
    "2. Pros: Does not assume order; widely supported.\n",
    "3. Cons: Can cause high dimensionality and sparse data when feature has many categories.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Nominal categorical data\n",
    "\n",
    "Linear Regression, Logistic Regression, SVM\n",
    "\n",
    "**Drawback**\n",
    "\n",
    "Increases number of columns (curse of dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce59d893-b228-4eb7-a3fb-121e2ba43340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Blue  Green    Red\n",
      "0  False  False   True\n",
      "1   True  False  False\n",
      "2  False   True  False\n",
      "3  False  False   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = ['Red', 'Blue', 'Green', 'Red']\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Color'])\n",
    "one_hot_encoded = pd.get_dummies(df['Color'])\n",
    "\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b77aa-92d8-4a55-8049-20ca378cc89b",
   "metadata": {},
   "source": [
    "# 3. Ordinal Encoding\n",
    "\n",
    "**Ordinal Encoding** maps categories to integers while preserving their natural order. This works well for ordered data like ratings but is not suitable for nominal variables.\n",
    "\n",
    "1. Used for ordered features like ratings or education levels.\n",
    "2. Pros: Maintains order; reduces dimensionality.\n",
    "3. Cons: Not suitable for nominal categories.\n",
    "\n",
    "When to Use\n",
    "\n",
    "Ordered categories\n",
    "\n",
    "ðŸ”¹ Example Columns\n",
    "\n",
    "size â†’ 1 BHK < 2 BHK < 3 BHK\n",
    "\n",
    "rating â†’ low < medium < high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ff5281-c8db-4291-a774-82bbe88caa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Ordinal Data: [[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data = [['Low'], ['Medium'], ['High'], ['Medium'], ['Low']]\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "print(f\"Encoded Ordinal Data: {encoded_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0be81-d2f4-407c-bbc5-3e0d04cc796f",
   "metadata": {},
   "source": [
    "# 4. Target Encoding\n",
    "**Target Encoding** also known as Mean Encoding is a technique where each category in a feature is replaced by the mean of the target variable for that category.\n",
    "\n",
    "1. Useful for high-cardinality features like ZIP codes or product IDs.\n",
    "2. Pros: Captures relationship to target variable.\n",
    "3. Cons: Risk of overfitting, also must apply smoothing/statistical techniques.\n",
    "\n",
    "When to Use\n",
    "\n",
    "High-cardinality features\n",
    "\n",
    "Regression problems\n",
    "\n",
    "Risk\n",
    "\n",
    "Data leakage if not done carefully\n",
    "\n",
    "ðŸ”¹ Example Columns\n",
    "\n",
    "location, society"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982f9d25-9e8e-4612-8359-49bbcb922042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Target Data:\n",
      "       City\n",
      "0  0.570926\n",
      "1  0.434946\n",
      "2  0.570926\n",
      "3  0.434946\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'City': ['London', 'Paris', 'London', 'Berlin'], 'Target': [1, 0, 1, 0]}\n",
    ")\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=['City'])\n",
    "df_tgt = encoder.fit_transform(df['City'], df['Target'])\n",
    "\n",
    "print(f\"Encoded Target Data:\\n{df_tgt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e5b34-04bd-401c-8691-5b7dea15f04a",
   "metadata": {},
   "source": [
    "# 5. Binary Encoding\n",
    "\n",
    "**Binary encoding** represents categories as binary codes and splits them across multiple columns. It is efficient for high-cardinality data but slightly more complex to implement.\n",
    "\n",
    "1. Applied in high-cardinality text/NLP tasks to save memory.\n",
    "2. Pros: Reduces dimensionality, more memory-efficient than one-hot encoding.\n",
    "3. Cons: Slightly more complex; requires careful handling of missing values.\n",
    "\n",
    "When to Use\n",
    "\n",
    "Large categorical columns\n",
    "\n",
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9050930f-94bb-4911-9749-60dc1f1328ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_0  Color_1\n",
      "0        0        1\n",
      "1        1        0\n",
      "2        1        1\n",
      "3        0        1\n"
     ]
    }
   ],
   "source": [
    "data = ['Red', 'Green', 'Blue', 'Red']\n",
    "encoder = ce.BinaryEncoder(cols=['Color'])\n",
    "encoded_data = encoder.fit_transform(pd.DataFrame(data, columns=['Color']))\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ef031-a840-4de4-95b5-1f7643d71063",
   "metadata": {},
   "source": [
    "# 6. Frequency Encoding\n",
    "\n",
    "**Frequency Encoding** assigns categories values based on how often they occur in the dataset. It is simple and compact but can introduce data leakage if applied improperly.\n",
    "\n",
    "1. Effective in retail, e-commerce or clickstream data for popularity trends.\n",
    "2. Pros: Low computational and storage requirements.\n",
    "3. Cons: Can introduce data leakage if not handled properly.\n",
    "\n",
    "When to Use\n",
    "\n",
    "High-cardinality columns\n",
    "\n",
    "Avoids dimensional explosion\n",
    "\n",
    "ðŸ”¹ Example Columns\n",
    "\n",
    "location\n",
    "\n",
    "society"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c429a9-a555-4c1d-b69f-08f47281dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Data: [np.int64(3), np.int64(1), np.int64(1), np.int64(3), np.int64(3)]\n"
     ]
    }
   ],
   "source": [
    "data = ['Red', 'Green', 'Blue', 'Red', 'Red']\n",
    "series_data = pd.Series(data)\n",
    "frequency_encoding = series_data.value_counts()\n",
    "\n",
    "encoded_data = [frequency_encoding[x] for x in data]\n",
    "print(\"Encoded Data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810179e-aa0f-4dc9-82f0-8c05717d118a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
